{"cells": [{"cell_type": "markdown", "source": ["# \ud83e\udde0 Seq2Seq Basic Training \u2013 Teaching Notebook\nThis notebook demonstrates how to train a basic Seq2Seq model using Keras."]}, {"cell_type": "code", "source": ["import tensorflow as tf\n", "from tensorflow.keras.models import Model\n", "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n", "from tensorflow.keras.preprocessing.sequence import pad_sequences\n", "from utils.tokenizer_utils import create_tokenizers, save_tokenizers\n", "\n", "# Load sample dataset\n", "lines = open(\"../data/french_english_pairs.txt\", encoding='utf-8').read().strip().split('\\n')\n", "input_texts, target_texts = zip(*[line.split('\\t') for line in lines])"]}, {"cell_type": "code", "source": ["# Tokenize\n", "tokenizer_in, tokenizer_out = create_tokenizers(input_texts, target_texts)\n", "input_seq = tokenizer_in.texts_to_sequences(input_texts)\n", "target_seq = tokenizer_out.texts_to_sequences(target_texts)\n", "max_len = 10\n", "encoder_input_data = pad_sequences(input_seq, maxlen=max_len, padding='post')\n", "decoder_input_data = pad_sequences(target_seq, maxlen=max_len, padding='post')"]}, {"cell_type": "code", "source": ["# Save tokenizers\n", "save_tokenizers(tokenizer_in, tokenizer_out, \"../utils/tokenizer_in.pkl\", \"../utils/tokenizer_out.pkl\")"]}, {"cell_type": "code", "source": ["# Build basic Seq2Seq model\n", "latent_dim = 128\n", "vocab_in = len(tokenizer_in.word_index) + 1\n", "vocab_out = len(tokenizer_out.word_index) + 1\n", "\n", "encoder_inputs = Input(shape=(None,))\n", "enc_emb = Embedding(vocab_in, latent_dim)(encoder_inputs)\n", "encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb)\n", "\n", "decoder_inputs = Input(shape=(None,))\n", "dec_emb = Embedding(vocab_out, latent_dim)(decoder_inputs)\n", "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n", "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n", "decoder_dense = Dense(vocab_out, activation='softmax')\n", "decoder_outputs = decoder_dense(decoder_outputs)\n", "\n", "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n", "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n", "model.fit([encoder_input_data, decoder_input_data], tf.expand_dims(decoder_input_data, -1), batch_size=2, epochs=30, verbose=1)\n", "model.save(\"../models/basic_seq2seq.h5\")"]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 2}